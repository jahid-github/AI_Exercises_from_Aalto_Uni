{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzq8JJWjrNm6xCmLe2sMrB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahid-github/AI_Exercises_from_Aalto_Uni/blob/main/Text_to_images_with_Stable_Diffusion_2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Auzvjdl9jYub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text to images with Stable Diffusion 2.1\n",
        "The model used in this demo is licensed with a CreativeML OpenRAIL++ license. The authors of the model claim no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in this license. The license forbids you from sharing any content that violates any laws, produce any harm to a person, disseminate any personal information that would be meant for harm, spread misinformation and target vulnerable groups. For the full list of restrictions please read the license.\n",
        "\n",
        "cover.png\n",
        "\n",
        "Introduction\n",
        "Stable Diffusion stems from a class of deep generative models called diffusion models which can generate images from random numbers (noise). To guide the image generation procedure, we can condition the model on some class label, e.g., 'cat', or a text description to generate images that should include things what we request. Stable Diffusion gets guidance from text prompts where it is up to the user to come up with clever prompts to obtain images with the correct content and desired style.\n",
        "\n",
        "In this exercise, we will generate images from written text prompts with a pre-trained Stable Diffusion model. We have implmented the following tasks for you to play around with:\n",
        "\n",
        "Generate your (potentially) first image with Stable Diffusion.\n",
        "Generate images using different number of inference steps\n",
        "Generate images with varying prompts\n",
        "Generate images with negative prompts\n",
        "Generate image with a text prompt and an initial image using the image-to-image version of Stable Diffusion\n",
        "We have provided some example text prompts for each task. Feel free to write your own text prompts to generate images.\n",
        "\n",
        "Stable Diffusion 2.1 was trained on the LAION-5B dataset filtered using LAION's NSFZ Detector to remove images with inappropriate content. Furthermore, they use hundreds of GPUs to train the model, which is one of the main reasons why we will use a pre-trained model to generate images.\n",
        "\n",
        "Be aware of that the image generation typically takes several minutes when you are using a CPU.\n",
        "\n",
        "(Optional) For further reading about Stable Diffusion:\n",
        "\n",
        "Blog post on how to run Stable Diffusion and an overview of the model components: https://huggingface.co/blog/stable_diffusion\n",
        "Guide on prompt engineering with Stable Diffusion and GPU memory optimization: https://huggingface.co/docs/diffusers/stable_diffusion\n",
        "Blog post on Stable Diffusion with visualizations and without math: https://jalammar.github.io/illustrated-stable-diffusion/\n",
        "Original paper by Rombach et al. published at CVPR 2022: https://arxiv.org/abs/2112.10752\n",
        "Getting started\n",
        "You first need to set up the environment and install some additional Python packages into it. Run the cells below by clcking on the play symbol on left side of the cell or by activating the cell and pressing SHIFT+ENTER on your keyboard.\n",
        "\n",
        "Installing the packages should take a minute or so."
      ],
      "metadata": {
        "id": "AOi8LNp4pKzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate scipy safetensors\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T_MPdyYpeZV",
        "outputId": "80b8afbc-24de-449d-92b2-9216edbfd163"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.29.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import helper functions\n",
        "We have placed most of the Python code into functions in the file helpers.py that executes the calls to Stable Diffusion for generating images, loading models and input images, and visualizing the generated images.\n",
        "\n",
        "Run the cell below to import the needed helper functions. Feel free to take a look in helpers.py if you are interested."
      ],
      "metadata": {
        "id": "lu1ggujJpmEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import helper functions\n",
        "from helpers import load_txt2img_model, generate_image_from_text_prompt\n",
        "from helpers import load_image, plot_images_and_inference_steps\n",
        "from helpers import plot_images_with_different_prompts, plot_images_with_negative_prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "gI3WcAqVpm77",
        "outputId": "c9af99b3-3191-4ebd-d518-c729bb00af53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'helpers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e1dade064efc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import helper functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_txt2img_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_image_from_text_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_images_and_inference_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_images_with_different_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_images_with_negative_prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helpers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Stable Diffusion model\n",
        "The trained Stable Diffusion model is hosted on Hugging Face. Running the cell below will set up things and load the model from '/coursedata' by setting model_id = \"/coursedata/stable-diffusion-2-base\" in the cell.\n",
        "\n",
        "The Stable Diffusion model will be defined in the object named pipe after running the cell with the appropriate model_id."
      ],
      "metadata": {
        "id": "NHBkv0pIpqYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model_id = \"/coursedata/stable-diffusion-2-base\"\n",
        "pipe = load_txt2img_model(model_id)"
      ],
      "metadata": {
        "id": "oiEKKxEspta0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the random seed\n",
        "The seed below specifies how to initialize the random number generator in the model. In addition to the text, Stable Diffusion is initialized with a fixed amount of \"random\" numbers, where the seed determines how these numbers should be drawn randomly. Setting the seed is a helpful tool when debugging machine learning models and algorithms.\n",
        "\n",
        "Run the cell below to set the seed. Feel free to set the seed to any non-negative number you wish.\n",
        "\n",
        "Note: You will generate different images for different seeds."
      ],
      "metadata": {
        "id": "jQCvuvL7pwSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "2zta7fO5pzDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Generate image with Stable Diffusion from text input\n",
        "Now you can generate images by inputting text of your choice to the Stable Diffusion model.\n",
        "\n",
        "The prompt below specifies the input and running the cell will pass it to the model and finally display the generated content.\n",
        "\n",
        "Note that the time to generate an image varies depending on the hardware that you have access to:\n",
        "\n",
        "Generating this image will take around 20 seconds per inference step (default: 25 steps) on JupyterHub."
      ],
      "metadata": {
        "id": "B8Ll_ybBp1Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The prompt is the text you input to the model, edit below\n",
        "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
        "\n",
        "# Run Stabe Diffusion with the provided input\n",
        "image = generate_image_from_text_prompt(pipe, prompt, seed=seed)\n",
        "\n",
        "# Display image within cell\n",
        "image\n",
        "\n",
        "# ... or save the output as a PNG\n",
        "#image.save(\"astronaut_rides_horse.png\")"
      ],
      "metadata": {
        "id": "KfS6vDoCp9ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Images from different inference steps\n",
        "We can inspect what the generated images look like at different number of inference steps. An inference step involves a forward pass of the the text prompt and the current image passed as input to Stable Diffusion. The first inference step involves inputting an image with random pixels together with the written text prompt to obtain the generated image. The subsequent inference steps then uses the last generated image as input together with the text prompt to refine the generated image.\n",
        "\n",
        "Given a text prompt, we will generate images at different inference steps and inspect the resulting output images by running the cell below.\n",
        "\n",
        "Be patient. Generating these images will take several minutes."
      ],
      "metadata": {
        "id": "_qzdxU4yqGYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The prompt is the text you input to the model, edit below\n",
        "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
        "\n",
        "# The different number of inference steps to test\n",
        "inference_steps = [1, 2, 4, 8, 16, 25]\n",
        "\n",
        "images = []\n",
        "for num_inference_steps in inference_steps:\n",
        "    # Generate image from the prompt for the given number of inference steps\n",
        "    image = generate_image_from_text_prompt(pipe, prompt,\n",
        "                                            num_inference_steps=num_inference_steps,\n",
        "                                            seed=seed)\n",
        "    images.append(image)"
      ],
      "metadata": {
        "id": "DQxeaopzqJ71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the generated images to inspect what they look like at different inference steps by running the cell below."
      ],
      "metadata": {
        "id": "zRB9-ugkqZ4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images_and_inference_steps(images, inference_steps, rows=2, cols=3)"
      ],
      "metadata": {
        "id": "uEHOdSPuqapz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Changing the text prompt\n",
        "We can add more descriptions for the image in the text prompt to further instruct Stable Diffusion on what type of generated image we want.\n",
        "\n",
        "In this task, we begin with a base text prompt and then extend the text prompt with different additional text prompts. We have provided four different additional prompts to try out.\n",
        "\n",
        "Feel free to change the base_prompt and additional_prompts. Place the additional prompts within quotation marks \"...\". You may also separate words with commas like \"high quality, cartoon\", which may help the model to recognize the given text prompt better."
      ],
      "metadata": {
        "id": "C5OPWsN-qcmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A base prompt with text that is the same for all generated images\n",
        "base_prompt = \"a photo of an astronaut riding a horse on mars\" # e.g. \"a photo of a man reading a book\"\n",
        "\n",
        "# Additional prompts to complement the base prompt\n",
        "additional_prompts = [\"blender\",\n",
        "                      \"blender, in the style of <midjourney>\",\n",
        "                      \"drawn by hand\",\n",
        "                      \"drawn by hand, in the style of <midjourney>\"]"
      ],
      "metadata": {
        "id": "Gy6YAho1qlJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to start generating images with the different text prompts."
      ],
      "metadata": {
        "id": "Xaa_jg2qql6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "for additional_prompt in additional_prompts:\n",
        "    # Extend the base prompt with the additional prompt\n",
        "    prompt = base_prompt + ', ' + additional_prompt\n",
        "    # Generate image from the base + additional prompt\n",
        "    image = generate_image_from_text_prompt(pipe,\n",
        "                                            prompt=prompt,\n",
        "                                            seed=seed)\n",
        "    images.append(image)"
      ],
      "metadata": {
        "id": "WzTD7vqlqo6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the generated images to inspect what how they differ given the different additional prompts by running the cell below."
      ],
      "metadata": {
        "id": "tFpwj2PBqrew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images_with_different_prompts(images, base_prompt, additional_prompts, rows=2, cols=2)"
      ],
      "metadata": {
        "id": "KNmcMK8kqu9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4: Add a negative prompt as input\n",
        "Stable Diffusion can use negative prompts to instruct the model of what it should not include in the generated images.\n",
        "\n",
        "In this task, we provide a text prompt to the model to instruct what type of images we want as well as a negative prompt where we tell the model what we want it to avoid generating. We have provided four different negative prompts to try out.\n",
        "\n",
        "Feel free to change the prompt and negative_prompts. Place the negative prompts within quotation marks \"...\". Adding several words separated by commas \"bad quality, cartoon\" may help the model to recognize the given negative text prompt better."
      ],
      "metadata": {
        "id": "7EEJ-XlBq4K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt to input to the model, edit below\n",
        "prompt = \"a painting of a vase with roses on a table next with an open book, oil on canvas, fine art, artistic style\"\n",
        "\n",
        "# Negative prompts for instructing the model what it should not include in the generated images\n",
        "negative_prompts = [\"\",\n",
        "                    \"in the style of <wrong>\",\n",
        "                    \"red\",\n",
        "                    \"red, in the style of <wrong>\"]"
      ],
      "metadata": {
        "id": "R1c__0SYrFWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to start generating images with the different negative prompts."
      ],
      "metadata": {
        "id": "gO5zMc73rInE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "for negative_prompt in negative_prompts:\n",
        "    # Generate image from the prompt and the negative prompt\n",
        "    image = generate_image_from_text_prompt(pipe,\n",
        "                                            prompt=prompt,\n",
        "                                            negative_prompt=negative_prompt,\n",
        "                                            num_inference_steps=num_inference_steps,\n",
        "                                            seed=seed)\n",
        "    images.append(image)"
      ],
      "metadata": {
        "id": "TdaIOmxErKwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the generated images to inspect what how they differ given the different negative prompts by running the cell below."
      ],
      "metadata": {
        "id": "zhcN-l3WrNN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images_with_negative_prompts(images, prompt, negative_prompts, rows=2, cols=2)"
      ],
      "metadata": {
        "id": "tTJmA4CirROk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5: Image-to-image Generation\n",
        "Stable Diffusion can generate images from a rough image sketches and text prompts. This is called image-to-image generation, where Stable Diffusion will refine an image template by filling it in with the infomration from the text prompt.\n",
        "\n",
        "In this example, our initial image will be a rough sketch made by the course personnel of the Aalto University logo on a green landscape with a river.\n",
        "\n",
        "Release memory\n",
        "Since the Stable Diffusion model is quite large (5GB), the notebook could crash if you load another model without releasing the memory of the first model due to the low memory limit we may have have access to.\n",
        "\n",
        "Run the following command that deletes the first model in pipe to release its memory before loading the image-to-image generation model."
      ],
      "metadata": {
        "id": "7OsN7oH1rTOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Release memory of previous model before loading image-to-image model\n",
        "del pipe"
      ],
      "metadata": {
        "id": "s0x7CuY3rX0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import helper functions and load model¶"
      ],
      "metadata": {
        "id": "apm459BxrbbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import helper functions\n",
        "from helpers import load_img2img_model, generate_image_from_text_prompt_and_initial_image\n",
        "\n",
        "# Load image-to-image Stable Diffusion model with the same model_id as above\n",
        "model_id = \"/coursedata/stable-diffusion-2-base\"\n",
        "pipe = load_img2img_model(model_id)"
      ],
      "metadata": {
        "id": "5qRhF2vBrcDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load initial image sketch\n",
        "Run the cell below to load and display the image that we will refine using a text prompt and Stable Diffusion."
      ],
      "metadata": {
        "id": "xoIxssQTrhqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image\n",
        "init_image = load_image('./img2img-aalto-input.png', height=640, width=640)\n",
        "\n",
        "# Display image\n",
        "init_image"
      ],
      "metadata": {
        "id": "RN192dlfrkTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to set the prompt and negative_prompt of what the refined image should look like."
      ],
      "metadata": {
        "id": "0T7MoAaSrk2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt to give as input to the model together with the initial image\n",
        "prompt = \"A fantasy landscape with a giant sculpture of the capital letter A and an exclamation mark in the middle, fresh, fantasy photograph, realistic, depth of field\"\n",
        "\n",
        "# Negative prompts for model to avoid generating in the image\n",
        "negative_prompt = \"in the style of <wrong>, watermark, green\" #\"blender, cropped, lowres, out of frame, blurry, bad art, blurred, watermark, clipart\""
      ],
      "metadata": {
        "id": "Zjh4tPK9rrRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to generate the image from the given prompts and initial sketch image.\n",
        "\n",
        "Feel free to play around with the hyperparameters strength and guidance_scale to tune the resulting output images. The strength (0-1) indicates how much the initial image should be transformed. The guidance_scale (>1) indicates how closely linked the generated images should be to the text prompt."
      ],
      "metadata": {
        "id": "pcGZNBPZrtwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "strength = 0.8 # how much should the initial image be changed\n",
        "guidance_scale = 7.5 # how linked are generated image to prompt\n",
        "\n",
        "# Generate and display image\n",
        "image = generate_image_from_text_prompt_and_initial_image(pipe,\n",
        "                                                          init_image=init_image,\n",
        "                                                          prompt=prompt,\n",
        "                                                          negative_prompt=negative_prompt,\n",
        "                                                          strength=strength,\n",
        "                                                          guidance_scale=guidance_scale,\n",
        "                                                          seed=seed)\n",
        "image"
      ],
      "metadata": {
        "id": "UcmpY_VFrwCH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}